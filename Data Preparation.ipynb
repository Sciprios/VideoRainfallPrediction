{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "This script splits the meteorological data into four training and four validation data sets:\n",
    "    1. Single frame\n",
    "    2. Extreme Frames\n",
    "    3. Middle Frames\n",
    "These will each be used for single frame, late fusion, early & slow fusion respectively.\n",
    "\n",
    "The split between training and validation will be made using time periods. Validation years are as follows:\n",
    "1. 1993\n",
    "2. 1996\n",
    "3. 1999\n",
    "4. 2002\n",
    "5. 2005\n",
    "6. 2008\n",
    "7. 2011\n",
    "8. 2014\n",
    "\n",
    "This is to encourage a range of training and validation data across the time frame of this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "To begin, the meteorological data is loaded from preextracted files into training and validation lists. These lists are then used to create training sets for each set highlighted in the introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_years = [1994, 1995, 1996, 1998, 1999, 2000, 2002, 2003, 2004, 2006, 2007, 2008, 2010, 2011, 2012, 2014, 2015]\n",
    "validation_years = [1997, 2001, 2005, 2009, 2013]\n",
    "\n",
    "data_folder = \"E:/31-12-2020/forecastee-data/\"\n",
    "rainfall_file = \"./data/rainfall/truth_rf.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(years, data_folder, rainfall_file):\n",
    "    \"\"\" This method loads the meteorology (mean sea level pressure and 2m Air temperature) and rainfall\n",
    "        for each year provided. For each month of that year the MSLP and 2m Air Temperature are combined into a single\n",
    "        matrix of size [2, time, 61, 121] and a 2D array of rainfall values for each month in the format\n",
    "        [month, year, region_0_rainfall, ..., region_12_rainfall].\n",
    "        Parameters:\n",
    "            years (list<int>): The years to be extracted for.\n",
    "            data_folder (string): Where is the meteorological data stored?\n",
    "            rainfall_file (string): Where is rainfall stored?\n",
    "        Returns:\n",
    "            List<Numpy Matrix>: List of monthly matrices of size [2, time, 61, 121].\n",
    "            Numpy Matrix: CEH-GEAR Rainfall values for each month required, in the format: \n",
    "                            [Month, Year, rain_region_0, ..., rain_region_12]\n",
    "            Numpy Matrix: Met Office Rainfall values for each month required, in the format: \n",
    "                            [Month, Year, rain_region_0, ..., rain_region_12]\"\"\"\n",
    "    monthly_meteo = []\n",
    "    monthly_rain = []\n",
    "    monthly_mo_rain = []\n",
    "    rainfall = np.load(\"./data/rainfall/truth_rf.npy\")\n",
    "    mo_rainfall = np.load(\"./data/rainfall/mo_rf.npy\")\n",
    "    for y in tqdm(years):\n",
    "        for m in range(1, 13):\n",
    "            month_data = []\n",
    "            try:\n",
    "                for v in ['msl', 't2m']:\n",
    "                    data_file = data_folder + \"{}/forecasted-months/{}-{}.npy\".format(v, m, y)\n",
    "                    data = np.load(data_file)\n",
    "                    if len(data.shape) != 3:\n",
    "                        data = data[0, :, :, :]\n",
    "                    month_data.append(data)\n",
    "                # Get rainfall values\n",
    "                mrain = rainfall[(rainfall[:, 0] == m) & (rainfall[:, 1] == y), :]\n",
    "                morain = mo_rainfall[(mo_rainfall[:, 0] == m) & (mo_rainfall[:, 1] == y), :]\n",
    "            except Exception as e:\n",
    "                print(\"Unable to load {}/{}-{}\".format(v, m, y))\n",
    "            else:\n",
    "                monthly_meteo.append(np.array(month_data))\n",
    "                monthly_rain.append(mrain)\n",
    "                monthly_mo_rain.append(morain)\n",
    "    return monthly_meteo, np.squeeze(monthly_rain), np.squeeze(monthly_mo_rain), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5708aa6e54347289375a2e6e8bb27f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc049f6a2b7b4fd2a0c0fd71f6d5a2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84287ce4296f48a6b3cf6a9ecb4f5fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_meteo_raw, training_rainfall, training_mo_rainfall = load_data(training_years, data_folder, rainfall_file)\n",
    "validation_meteo_raw, validation_rainfall, validation_mo_rainfall = load_data(validation_years, data_folder, rainfall_file)\n",
    "all_meteo_raw, all_rainfall, all_mo_rainfall = load_data(range(1994, 2016), data_folder, rainfall_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation Methods\n",
    "\n",
    "The methods defined below split a given list of numpy matrices into a regular-sized training matrix. After extracting each data set they are saved for use later. Firstly, we define a folder to hold the resulting data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data_folder = \"D:/PHD_DATA/Video_01-03-2021/prepared-data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the mean and standard deviation profiles are extracted for both MSLP and 2AT. (0, 61, 121) = means, (1, 61, 121) = stds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a506c24cd3744fcba759dc66b9dc4501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=264.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def combine_all(meteo_data):\n",
    "    combined_patterns = None\n",
    "    for md in tqdm(meteo_data):\n",
    "        if combined_patterns is None:\n",
    "            combined_patterns = md\n",
    "        else:\n",
    "            combined_patterns = np.concatenate((combined_patterns, md), axis=1)\n",
    "    return combined_patterns\n",
    "\n",
    "def get_stats(meteo_data, output_folder=\"D:/PHD_DATA/Video_01-03-2021/prepared-data/\"):\n",
    "    if not os.path.exists(output_folder + \"stats.npy\"):\n",
    "        combined_patterns = combine_all(meteo_data)\n",
    "        means, stds = np.mean(combined_patterns, axis=1), np.std(combined_patterns, axis=1)\n",
    "        np.save(output_folder + \"stats.npy\", np.array([means, stds]))\n",
    "    return np.load(output_folder + \"stats.npy\")\n",
    "    \n",
    "stats = get_stats(all_meteo_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Single Frame\n",
    "\n",
    "This first method averages across all days in each month to provide an average forecast MSLP and 2AT. The validation and training sets are then saved under the names defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = prepared_data_folder + \"single_train.npy\"\n",
    "validation_file = prepared_data_folder + \"single_valid.npy\"\n",
    "all_file = prepared_data_folder + \"single_all.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_frame(monthly_data, stats):\n",
    "    \"\"\" Averages across each matrix in the time dimension to produce a new\n",
    "        matrix such that all matrices in the list are of equal size.\n",
    "        Parameters:\n",
    "            - monthly_data List<Numpy Matrix>: The matrices, each should have a size of [2, time, 61, 121].\n",
    "            - stats Numpy Matrix (2, 2, 61, 121): The MSLP & 2AT means (0), and standard deviations (1) of each pixel.\n",
    "        Returns:\n",
    "            Numpy Matrix:   A matrix containing all aggregated data from the input through taking the mean of\n",
    "                            the time dimension. Size: [no. months, 2, 61, 121]\"\"\"\n",
    "    composite_matrices = []\n",
    "    for m in monthly_data:\n",
    "        data = np.mean(m, axis=1)\n",
    "        composite_matrices.append(((data - stats[0, :, :, :]) / stats[1, :, :, :]))\n",
    "    return composite_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_single = single_frame(training_meteo_raw, stats)\n",
    "validation_single = single_frame(validation_meteo_raw, stats)\n",
    "all_single = single_frame(all_meteo_raw, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(training_file, training_single)\n",
    "np.save(validation_file, validation_single)\n",
    "np.save(all_file, all_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Middle Frames\n",
    "\n",
    "This final method takes the middle 28 days of data and combines them into a single matrix. 28 days is chosen because this is the minimum number of days in a month. These are then also saved as separate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = prepared_data_folder + \"middle_train.npy\"\n",
    "validation_file = prepared_data_folder + \"middle_valid.npy\"\n",
    "all_file = prepared_data_folder + \"middle_all.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def middle_frames(monthly_data, stats):\n",
    "    \"\"\" Takes the middle 28 entries across the time dimension in each matrix to produce a new\n",
    "        matrix such that all matrices in the list are of equal size.\n",
    "        Parameters:\n",
    "            - monthly_data List<Numpy Matrix>: The matrices, each should have a size of [2, time, 61, 121].\n",
    "            - stats Numpy Matrix (2, 2, 61, 121): The MSLP & 2AT means (0), and standard deviations (1) of each pixel.\n",
    "        Returns:\n",
    "            Numpy Matrix:   A matrix containing all aggregated data from the input through taking the mean of\n",
    "                            the time dimension. Size: [no. months, 2, 56, 61, 121]\"\"\"\n",
    "    matrices = []\n",
    "    for m in monthly_data:\n",
    "        start_index = m.shape[1] - 28\n",
    "        stand_matrix = m[:, start_index:start_index+28, :, :]\n",
    "        for n in range(0, 28):\n",
    "            stand_matrix[:, n, :, :] = ((stand_matrix[:, n, :, :] - stats[0, :, :, :]) / stats[1, :, :, :])\n",
    "        matrices.append(stand_matrix)\n",
    "    return np.array(matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_middle = middle_frames(training_meteo_raw, stats)\n",
    "validation_middle = middle_frames(validation_meteo_raw, stats)\n",
    "all_middle = middle_frames(all_meteo_raw, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(training_file, training_middle)\n",
    "np.save(validation_file, validation_middle)\n",
    "np.save(all_file, all_middle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Rainfall\n",
    "\n",
    "Now, save the rainfall values in training and validation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = prepared_data_folder + \"expected_train.npy\"\n",
    "validation_file = prepared_data_folder + \"expected_valid.npy\"\n",
    "all_file = prepared_data_folder + \"expected_all.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(training_file, training_rainfall)\n",
    "np.save(validation_file, validation_rainfall)\n",
    "np.save(all_file, all_rainfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = prepared_data_folder + \"mo_train.npy\"\n",
    "validation_file = prepared_data_folder + \"mo_valid.npy\"\n",
    "all_file = prepared_data_folder + \"mo_all.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(training_file, training_mo_rainfall)\n",
    "np.save(validation_file, validation_mo_rainfall)\n",
    "np.save(all_file, all_mo_rainfall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we standardize the rainfall based on region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(rainfall, output_folder=\"D:/PHD_DATA/Video_25-02-2021/prepared-data/\"):\n",
    "    if not os.path.exists(output_folder + \"rainfall_stats.npy\"):\n",
    "        mins = np.min(rainfall[:, 2:], axis=0)\n",
    "        maxs = np.max(rainfall[:, 2:], axis=0)\n",
    "        np.save(output_folder + \"rainfall_stats.npy\", np.array([mins, maxs]).T)\n",
    "    return np.load(output_folder + \"rainfall_stats.npy\")\n",
    "\n",
    "rainfall_stats = get_stats(all_rainfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_regionally(rainfall, stats):\n",
    "    rainfall = rainfall.T[2:, :]\n",
    "    mins = np.repeat(stats[:, 0], rainfall.shape[1]).reshape((13, rainfall.shape[1]))\n",
    "    maxs = np.repeat(stats[:, 1], rainfall.shape[1]).reshape((13, rainfall.shape[1]))\n",
    "    rainfall = (rainfall - mins) / (maxs-mins)\n",
    "    return rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = prepared_data_folder + \"expected_train_standardized.npy\"\n",
    "validation_file = prepared_data_folder + \"expected_valid_standardized.npy\"\n",
    "all_file = prepared_data_folder + \"expected_all_standardized.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(training_file, scale_regionally(training_rainfall, rainfall_stats))\n",
    "np.save(validation_file, scale_regionally(validation_rainfall, rainfall_stats))\n",
    "np.save(all_file, scale_regionally(all_rainfall, rainfall_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = prepared_data_folder + \"mo_train_standardized.npy\"\n",
    "validation_file = prepared_data_folder + \"mo_valid_standardized.npy\"\n",
    "all_file = prepared_data_folder + \"mo_all_standardized.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(training_file, scale_regionally(training_mo_rainfall, rainfall_stats))\n",
    "np.save(validation_file, scale_regionally(validation_mo_rainfall, rainfall_stats))\n",
    "np.save(all_file, scale_regionally(all_mo_rainfall, rainfall_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
