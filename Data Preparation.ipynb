{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "This script splits the meteorological data into four training and four validation data sets:\n",
    "    1. Single frame\n",
    "    2. Extreme Frames\n",
    "    3. Middle Frames\n",
    "These will each be used for single frame, late fusion, early & slow fusion respectively.\n",
    "\n",
    "The split between training and validation will be made using time periods. Validation years are as follows:\n",
    "1. 1993\n",
    "2. 1996\n",
    "3. 1999\n",
    "4. 2002\n",
    "5. 2005\n",
    "6. 2008\n",
    "7. 2011\n",
    "8. 2014\n",
    "\n",
    "This is to encourage a range of training and validation data across the time frame of this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "To begin, the meteorological data is loaded from preextracted files into training and validation lists. These lists are then used to create training sets for each set highlighted in the introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_years = [1994, 1995, 1997, 1998, 2000, 2001, 2003, 2004, 2006, 2007, 2009, 2010, 2012, 2013, 2015]\n",
    "validation_years = [1993, 1996, 1999, 2002, 2005, 2008, 2011, 2014]\n",
    "\n",
    "data_folder = \"E:/31-12-2020/forecastee-data/\"\n",
    "rainfall_file = \"./data/rainfall/truth_rf.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(years, data_folder, rainfall_file):\n",
    "    \"\"\" This method loads the meteorology (mean sea level pressure and 2m Air temperature) and rainfall\n",
    "        for each year provided. For each month of that year the MSLP and 2m Air Temperature are combined into a single\n",
    "        matrix of size [2, time, 61, 121] and a 2D array of rainfall values for each month in the format\n",
    "        [month, year, region_0_rainfall, ..., region_12_rainfall].\n",
    "        Parameters:\n",
    "            years (list<int>): The years to be extracted for.\n",
    "            data_folder (string): Where is the meteorological data stored?\n",
    "            rainfall_file (string): Where is rainfall stored?\n",
    "        Returns:\n",
    "            List<Numpy Matrix>: List of monthly matrices of size [2, time, 61, 121].\n",
    "            Numpy Matrix: CEH-GEAR Rainfall values for each month required, in the format: \n",
    "                            [Month, Year, rain_region_0, ..., rain_region_12]\"\"\"\n",
    "    monthly_meteo = []\n",
    "    monthly_rain = []\n",
    "    rainfall = np.load(\"./data/rainfall/truth_rf.npy\")\n",
    "    for y in tqdm(years):\n",
    "        for m in range(1, 13):\n",
    "            month_data = []\n",
    "            try:\n",
    "                for v in ['msl', 't2m']:\n",
    "                    data_file = data_folder + \"{}/forecasted-months/{}-{}.npy\".format(v, m, y)\n",
    "                    data = np.load(data_file)\n",
    "                    if len(data.shape) != 3:\n",
    "                        data = data[0, :, :, :]\n",
    "                    month_data.append(data)\n",
    "                # Get rainfall values\n",
    "                mrain = rainfall[(rainfall[:, 0] == m) & (rainfall[:, 1] == y), :]\n",
    "            except Exception as e:\n",
    "                print(\"Unable to load {}/{}-{}\".format(v, m, y))\n",
    "            else:\n",
    "                monthly_meteo.append(np.array(month_data))\n",
    "                monthly_rain.append(mrain)\n",
    "    return monthly_meteo, np.squeeze(monthly_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b08fbb2ec44f838b800a561a8293fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82638fd664e3492394a5aa1a24be1b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to load msl/1-1993\n",
      "Unable to load msl/2-1993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_meteo_raw, training_rainfall = load_data(training_years, data_folder, rainfall_file)\n",
    "validation_meteo_raw, validation_rainfall = load_data(validation_years, data_folder, rainfall_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation Methods\n",
    "\n",
    "The methods defined below split a given list of numpy matrices into a regular-sized training matrix. After extracting each data set they are saved for use later. Firstly, we define a folder to hold the resulting data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data_folder = \"E:/31-12-2020/prepared-data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Single Frame\n",
    "\n",
    "This first method averages across all days in each month to provide an average forecast MSLP and 2AT. The validation and training sets are then saved under the names defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = prepared_data_folder + \"single_train.npy\"\n",
    "validation_file = prepared_data_folder + \"single_valid.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_frame(monthly_data):\n",
    "    \"\"\" Averages across each matrix in the time dimension to produce a new\n",
    "        matrix such that all matrices in the list are of equal size.\n",
    "        Parameters:\n",
    "            - monthly_data List<Numpy Matrix>: The matrices, each should have a size of [2, time, 61, 121].\n",
    "        Returns:\n",
    "            Numpy Matrix:   A matrix containing all aggregated data from the input through taking the mean of\n",
    "                            the time dimension. Size: [no. months, 2, 61, 121]\"\"\"\n",
    "    composite_matrices = []\n",
    "    for m in monthly_data:\n",
    "        data = np.mean(m, axis=1)\n",
    "        composite_matrices.append(data)\n",
    "    return composite_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_single = single_frame(training_meteo_raw)\n",
    "validation_single = single_frame(validation_meteo_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(training_file, training_single)\n",
    "np.save(validation_file, validation_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Extreme Frame\n",
    "\n",
    "This next method takes the first and last frames (days) of each month. These are then saved in files defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = prepared_data_folder + \"extreme_train.npy\"\n",
    "validation_file = prepared_data_folder + \"extreme_valid.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extreme_frames(monthly_data):\n",
    "    \"\"\" Takes the first and last entries across the time dimension in each matrix to produce a new\n",
    "        matrix such that all matrices in the list are of equal size.\n",
    "        Parameters:\n",
    "            - monthly_data List<Numpy Matrix>: The matrices, each should have a size of [2, time, 61, 121].\n",
    "        Returns:\n",
    "            Numpy Matrix:   A matrix containing all aggregated data from the input through taking the mean of\n",
    "                            the time dimension. Size: [no. months, 2, 4, 61, 121]\"\"\"\n",
    "    matrices = []\n",
    "    for m in monthly_data:\n",
    "        month_matrix = np.zeros((2, 2, 61, 121))\n",
    "        month_matrix[0, :, :, :] = m[:, 0, :, :]\n",
    "        month_matrix[1, :, :, :] = m[:, -1, :, :]\n",
    "        matrices.append(month_matrix)\n",
    "    return np.array(matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_extreme = extreme_frames(training_meteo_raw)\n",
    "validation_extreme = extreme_frames(validation_meteo_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(training_file, training_extreme)\n",
    "np.save(validation_file, validation_extreme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Middle Frames\n",
    "\n",
    "This final method takes the middle 28 days of data and combines them into a single matrix. 28 days is chosen because this is the minimum number of days in a month. These are then also saved as separate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = prepared_data_folder + \"middle_train.npy\"\n",
    "validation_file = prepared_data_folder + \"middle_valid.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def middle_frames(monthly_data):\n",
    "    \"\"\" Takes the middle 28 entries across the time dimension in each matrix to produce a new\n",
    "        matrix such that all matrices in the list are of equal size.\n",
    "        Parameters:\n",
    "            - monthly_data List<Numpy Matrix>: The matrices, each should have a size of [2, time, 61, 121].\n",
    "        Returns:\n",
    "            Numpy Matrix:   A matrix containing all aggregated data from the input through taking the mean of\n",
    "                            the time dimension. Size: [no. months, 2, 56, 61, 121]\"\"\"\n",
    "    matrices = []\n",
    "    for m in monthly_data:\n",
    "        start_index = m.shape[1] - 28\n",
    "        matrices.append(m[:, start_index:start_index+28, :, :])\n",
    "    return np.array(matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_middle = middle_frames(training_meteo_raw)\n",
    "validation_middle = middle_frames(validation_meteo_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(training_file, training_middle)\n",
    "np.save(validation_file, validation_middle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Rainfall\n",
    "\n",
    "Now, save the rainfall values in training and validation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = prepared_data_folder + \"expected_train.npy\"\n",
    "validation_file = prepared_data_folder + \"expected_valid.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(training_file, training_rainfall)\n",
    "np.save(validation_file, validation_rainfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
