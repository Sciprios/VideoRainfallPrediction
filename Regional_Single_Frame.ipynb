{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Frame Model\n",
    "\n",
    "This script trains a single frame model based on an average image taken across the the forcasted month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D, LayerNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import initializers\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Define Region\n",
    "\n",
    "First, define a region to train a model for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = [\"ES\",\"NS\",\"WS\",\"EM\",\"EE\",\"LD\",\"NEE\",\"NWE\",\"SEE\",\"SWE\",\"WAL\",\"WM\",\"YH\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "To begin, data for a single frame mnodel must be loaded along with the expected regional rainfall values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 New Training Data\n",
    "\n",
    "This section loads the new training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datafile = \"D:/PHD_DATA/Video_18-01-2021/prepared-data/single_all.npy\"\n",
    "training_rainfallfile = \"D:/PHD_DATA/Video_18-01-2021/prepared-data/expected_all.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_videos = np.load(training_datafile)\n",
    "training_rainfall = np.load(training_rainfallfile)[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_videos = np.swapaxes(training_videos, 1, 2)\n",
    "training_videos = np.swapaxes(training_videos, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_videos[:, :, :, 0] = (training_videos[:, :, :, 0] - np.min(training_videos[:, :, :, 0])) / (np.max(training_videos[:, :, :, 0]) - np.min(training_videos[:, :, :, 0]))\n",
    "training_videos[:, :, :, 1] = (training_videos[:, :, :, 1] - np.min(training_videos[:, :, :, 1])) / (np.max(training_videos[:, :, :, 1]) - np.min(training_videos[:, :, :, 1]))\n",
    "\n",
    "for n in range(0, len(REGIONS)):\n",
    "    training_rainfall[:, n] = (training_rainfall[:, n] - np.min(training_rainfall[:, n])) / (np.max(training_rainfall[:, n]) - np.min(training_rainfall[:, n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.min(training_rainfall, axis=0))\n",
    "print(np.max(training_rainfall, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_augmentation(raw_rain, raw_vids):\n",
    "    vids = np.copy(raw_vids)\n",
    "    vids = vids + np.random.normal(0, 0.05, vids.shape)\n",
    "    return np.concatenate((raw_vids, vids), axis=0), np.concatenate((raw_rain, raw_rain), axis=0)\n",
    "\n",
    "APPLY_AUGMENTATION = True\n",
    "\n",
    "if APPLY_AUGMENTATION:\n",
    "    training_videos, training_rainfall = apply_augmentation(training_rainfall, training_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(548, 61, 121, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_videos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definition\n",
    "\n",
    "Next, a CNN model architecture is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generator(input_shape=(2, 61, 121), learning_rate=0.1):\n",
    "    \"\"\" This method generates a model definition. \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First layer\n",
    "    model.add(Conv2D(8, (2, 2), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Second layer\n",
    "    model.add(Conv2D(8, (2, 2), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Third layer\n",
    "    model.add(Conv2D(8, (2, 2), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Final Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Setup training mechanism\n",
    "    model.compile(\n",
    "        loss=\"mean_squared_error\",\n",
    "        optimizer=Adam(learning_rate=learning_rate))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "Finally, training the model using the single framed data and opening a tensorboard instance with details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(run_name, tensorboard, model, xdata, ydata, models_folder=\"D:/PHD_DATA/Video_18-01-2021/models/\"):\n",
    "    \"\"\" Trains the given model with the given dataset. \"\"\"\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "    history = model.fit(\n",
    "        xdata,\n",
    "        ydata,\n",
    "        batch_size=8,\n",
    "        validation_split=0.3,\n",
    "        callbacks=[tensorboard, es],\n",
    "        epochs=100\n",
    "    )\n",
    "    save_model(model, models_folder + run_name + \".mdl\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexible parameters\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/48 [==============================] - 7s 108ms/step - loss: 0.0822 - val_loss: 0.0314\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 2s 38ms/step - loss: 0.0284 - val_loss: 0.0307\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 2s 35ms/step - loss: 0.0300 - val_loss: 0.0306\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 2s 36ms/step - loss: 0.0310 - val_loss: 0.0303\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 2s 37ms/step - loss: 0.0279 - val_loss: 0.0310\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 2s 36ms/step - loss: 0.0250 - val_loss: 0.0310\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 2s 37ms/step - loss: 0.0281 - val_loss: 0.0299\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 2s 37ms/step - loss: 0.0264 - val_loss: 0.0297\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 2s 37ms/step - loss: 0.0286 - val_loss: 0.0304\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 2s 37ms/step - loss: 0.0249 - val_loss: 0.0299\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 2s 36ms/step - loss: 0.0292 - val_loss: 0.0298\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 2s 37ms/step - loss: 0.0235 - val_loss: 0.0296\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 2s 36ms/step - loss: 0.0276 - val_loss: 0.0291\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 2s 37ms/step - loss: 0.0231 - val_loss: 0.0294\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 2s 37ms/step - loss: 0.0248 - val_loss: 0.0288\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 2s 41ms/step - loss: 0.0252 - val_loss: 0.0292\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0263 - val_loss: 0.0287\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 1s 23ms/step - loss: 0.0228 - val_loss: 0.0289\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 2s 37ms/step - loss: 0.0232 - val_loss: 0.0286\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 2s 39ms/step - loss: 0.0245 - val_loss: 0.0286\n",
      "Epoch 21/100\n",
      "40/48 [========================>.....] - ETA: 0s - loss: 0.023 - ETA: 0s - loss: 0.0235"
     ]
    }
   ],
   "source": [
    "final_errors = {}\n",
    "# Run model for each region\n",
    "for ridx, r in enumerate(REGIONS):\n",
    "    final_errors[r] = {}\n",
    "    # Run each model multiple times\n",
    "    for i in range(0, 3):\n",
    "        run_name = \"{}-{}\".format(r, int(time.time()))\n",
    "        tb = TensorBoard(log_dir=\"D:/PHD_DATA/Video_11-02-2021/SingleFrame/logs/{}\".format(run_name))\n",
    "        model = model_generator(learning_rate=learning_rate, input_shape=training_videos.shape[1:])\n",
    "        history = train_model(run_name, tb, model, training_videos, training_rainfall[:, ridx],\n",
    "                              models_folder=\"D:/PHD_DATA/Video_11-02-2021/SingleFrame/models/\")\n",
    "        final_errors[r][run_name] = history.history[\"val_loss\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
