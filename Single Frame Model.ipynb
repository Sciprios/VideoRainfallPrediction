{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Frame Model\n",
    "\n",
    "This script trains a single frame model based on an average image taken across the the forcasted month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D, LayerNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import initializers\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "To begin, data for a single frame mnodel must be loaded along with the expected regional rainfall values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 New Training Data\n",
    "\n",
    "This section loads the new training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datafile = \"D:/PHD_DATA/Video_18-01-2021/prepared-data/single_all.npy\"\n",
    "training_rainfallfile = \"D:/PHD_DATA/Video_18-01-2021/prepared-data/expected_all.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_videos = np.load(training_datafile)\n",
    "training_rainfall = np.load(training_rainfallfile)[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_videos = np.swapaxes(training_videos, 1, 2)\n",
    "training_videos = np.swapaxes(training_videos, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_videos[:, :, :, 0] = (training_videos[:, :, :, 0] - np.min(training_videos[:, :, :, 0])) / (np.max(training_videos[:, :, :, 0]) - np.min(training_videos[:, :, :, 0]))\n",
    "training_videos[:, :, :, 1] = (training_videos[:, :, :, 1] - np.min(training_videos[:, :, :, 1])) / (np.max(training_videos[:, :, :, 1]) - np.min(training_videos[:, :, :, 1]))\n",
    "\n",
    "#for n in range(0, 13):\n",
    "    #training_rainfall[:, n] = (training_rainfall[:, n] - np.mean(training_rainfall[:, n])) / np.std(training_rainfall[:, n])\n",
    "    #training_rainfall[:, n] = (training_rainfall[:, n] - np.min(training_rainfall[:, n])) / (np.max(training_rainfall[:, n]) - np.min(training_rainfall[:, n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 DEPRECATED\n",
    "\n",
    "This following section uses two separate datasets. Which is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_datafile = \"E:/31-12-2020/prepared-data/single_train.npy\"\n",
    "#validation_datafile = \"E:/31-12-2020/prepared-data/single_valid.npy\"\n",
    "#\n",
    "#training_rainfallfile = \"E:/31-12-2020/prepared-data/expected_train.npy\"\n",
    "#validation_rainfallfile = \"E:/31-12-2020/prepared-data/expected_valid.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_videos = np.load(training_datafile)\n",
    "#validation_videos = np.load(validation_datafile)\n",
    "#\n",
    "#training_rainfall = np.load(training_rainfallfile)[:, 2:]\n",
    "#validation_rainfall = np.load(validation_rainfallfile)[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need them in X, Y, COLOURS\n",
    "#training_videos = np.swapaxes(training_videos, 1, 2)\n",
    "#training_videos = np.swapaxes(training_videos, 2, 3)\n",
    "#\n",
    "#validation_videos = np.swapaxes(validation_videos, 1, 2)\n",
    "#validation_videos = np.swapaxes(validation_videos, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "#training_videos[:, :, :, 0] = (training_videos[:, :, :, 0] - np.min(training_videos[:, :, :, 0])) / (np.max(training_videos[:, :, :, 0]) - np.min(training_videos[:, :, :, 0]))\n",
    "#training_videos[:, :, :, 1] = (training_videos[:, :, :, 1] - np.min(training_videos[:, :, :, 1])) / (np.max(training_videos[:, :, :, 1]) - np.min(training_videos[:, :, :, 1]))\n",
    "#\n",
    "#validation_videos[:, :, :, 0] = (validation_videos[:, :, :, 0] - np.min(validation_videos[:, :, :, 0])) / (np.max(validation_videos[:, :, :, 0]) - np.min(validation_videos[:, :, :, 0]))\n",
    "#validation_videos[:, :, :, 1] = (validation_videos[:, :, :, 1] - np.min(validation_videos[:, :, :, 1])) / (np.max(validation_videos[:, :, :, 1]) - np.min(validation_videos[:, :, :, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definition\n",
    "\n",
    "Next, a CNN model architecture is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generator(input_shape=(2, 61, 121), learning_rate=0.1):\n",
    "    \"\"\" This method generates a model definition. \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First layer\n",
    "    #model.add(Conv2D(16, (2, 2), input_shape=input_shape, kernel_initializer=initializers.Ones()))\n",
    "    model.add(Conv2D(16, (2, 2), input_shape=input_shape, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Second layer\n",
    "    model.add(Conv2D(16, (2, 2), input_shape=input_shape, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Third layer\n",
    "    model.add(Conv2D(16, (2, 2), input_shape=input_shape, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Final Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(13, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=1, seed=None)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Setup training mechanism\n",
    "    model.compile(\n",
    "        loss=\"mean_squared_error\",\n",
    "        optimizer=Adam(learning_rate=learning_rate))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "Finally, training the model using the single framed data and opening a tensorboard instance with details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(run_name, tensorboard, model, xdata, ydata, models_folder=\"D:/PHD_DATA/Video_18-01-2021/models/\"):\n",
    "    \"\"\" Trains the given model with the given dataset. \"\"\"\n",
    "    history = model.fit(\n",
    "        xdata,\n",
    "        ydata,\n",
    "        batch_size=2,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[tensorboard],\n",
    "        epochs=50\n",
    "    )\n",
    "    save_model(model, models_folder + run_name + \".mdl\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexible parameters\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "110/110 [==============================] - 6s 46ms/step - loss: 7781.9374 - val_loss: 7750.2769\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 4973.2500 - val_loss: 4918.3154\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 3593.7988 - val_loss: 3620.4668\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2719.9181 - val_loss: 3115.1201\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 2142.8862 - val_loss: 2864.2007\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2293.9282 - val_loss: 2731.3508\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2170.9590 - val_loss: 2651.0527\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2091.8484 - val_loss: 2619.6599\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2161.0407 - val_loss: 2561.0305\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1928.6962 - val_loss: 2533.9866\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2126.9287 - val_loss: 2538.7957\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2267.9759 - val_loss: 2621.6587\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2014.8103 - val_loss: 2510.3965\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2324.1116 - val_loss: 2501.9121\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1988.7385 - val_loss: 2443.9578\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1950.9423 - val_loss: 2424.2029\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2378.1610 - val_loss: 2485.4045\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1914.6129 - val_loss: 2420.6699\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2108.9561 - val_loss: 2429.4910\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1977.3961 - val_loss: 2414.9924\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2108.5040 - val_loss: 2423.4875\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1900.2721 - val_loss: 2476.8494\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1954.7210 - val_loss: 2393.8259\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2026.8000 - val_loss: 2399.1401\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2088.7423 - val_loss: 2459.2881\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2032.0193 - val_loss: 2376.9888\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1959.3514 - val_loss: 2350.7271\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1885.5036 - val_loss: 2382.0166\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1950.8152 - val_loss: 2386.4045\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2040.6158 - val_loss: 2413.9326\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1902.0154 - val_loss: 2363.8923\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1943.4786 - val_loss: 2352.5728\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1927.4452 - val_loss: 2341.5332\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2020.3498 - val_loss: 2355.9084\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1865.8016 - val_loss: 2346.4490\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1875.5387 - val_loss: 2370.2419\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 1954.7019 - val_loss: 2365.5740\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1901.1903 - val_loss: 2363.0039\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2099.7082 - val_loss: 2330.3708\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1932.6759 - val_loss: 2337.7805\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2260.7956 - val_loss: 2428.4902\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2105.5777 - val_loss: 2356.3579\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1771.0519 - val_loss: 2358.7993\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2004.3708 - val_loss: 2341.5967\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2135.8091 - val_loss: 2413.5281\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1981.5445 - val_loss: 2353.1633\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1937.9172 - val_loss: 2341.5693\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2211.8851 - val_loss: 2386.8352\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2209.0206 - val_loss: 2340.4910\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1964.5311 - val_loss: 2355.4653\n",
      "INFO:tensorflow:Assets written to: D:/PHD_DATA/Video_18-01-2021/models/TEST-SL_16_16_16__13__22_t-1611306310.mdl\\assets\n",
      "Final loss: 2355.46533203125\n",
      "Epoch 1/50\n",
      "110/110 [==============================] - 7s 48ms/step - loss: 6896.8801 - val_loss: 5937.2114\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 4246.5786 - val_loss: 4108.8501\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2635.5253 - val_loss: 3375.3147\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2766.1132 - val_loss: 3041.2886\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2419.6495 - val_loss: 2813.6179\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 2278.6214 - val_loss: 2638.4497\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2279.1918 - val_loss: 2679.2224\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1903.6573 - val_loss: 2447.9128\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2069.3379 - val_loss: 2442.3870\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1833.0373 - val_loss: 2393.0691\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1969.6249 - val_loss: 2379.1833\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1976.5367 - val_loss: 2421.2246\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2020.2387 - val_loss: 2304.1826\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2080.0021 - val_loss: 2280.0259\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1884.9531 - val_loss: 2254.6108\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1750.9474 - val_loss: 2298.0415\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1990.8149 - val_loss: 2249.4043\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2004.4466 - val_loss: 2275.7173\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1896.7542 - val_loss: 2303.4397\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1993.6250 - val_loss: 2244.6904\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 2047.1423 - val_loss: 2296.1367\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1886.4730 - val_loss: 2224.0840\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1901.1628 - val_loss: 2273.3340\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1921.0270 - val_loss: 2308.6465\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 2s 20ms/step - loss: 1963.2184 - val_loss: 2224.3252\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1844.8477 - val_loss: 2217.6616\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1784.4672 - val_loss: 2203.1650\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1865.7498 - val_loss: 2276.8708\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1874.2506 - val_loss: 2209.4475\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1595.1468 - val_loss: 2220.4023\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1898.5232 - val_loss: 2192.6465\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1631.0497 - val_loss: 2185.3735\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2004.1585 - val_loss: 2186.3557\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2041.5763 - val_loss: 2227.8235\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1826.6683 - val_loss: 2191.4658\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 2064.2229 - val_loss: 2216.2373\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1886.9531 - val_loss: 2191.0850\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 1843.8707 - val_loss: 2181.2539\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1767.2492 - val_loss: 2162.9216\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1832.4331 - val_loss: 2180.0532\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 2s 23ms/step - loss: 1715.1093 - val_loss: 2213.9368\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 2099.0825 - val_loss: 2189.9294\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 1984.6723 - val_loss: 2188.2712\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 1820.2404 - val_loss: 2150.8904\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 1799.7828 - val_loss: 2174.6309\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 1667.8126 - val_loss: 2182.7576\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1710.1414 - val_loss: 2154.8206\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 1949.1748 - val_loss: 2169.8018\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 1713.1537 - val_loss: 2166.6475\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 1637.1582 - val_loss: 2189.4565\n",
      "INFO:tensorflow:Assets written to: D:/PHD_DATA/Video_18-01-2021/models/TEST-SL_16_16_16__13__22_t-1611306435.mdl\\assets\n",
      "Final loss: 2189.45654296875\n",
      "Epoch 1/50\n",
      "110/110 [==============================] - 7s 49ms/step - loss: 6613.9012 - val_loss: 6489.4614\n",
      "Epoch 2/50\n",
      " 70/110 [==================>...........] - ETA: 0s - loss: 4973.9992"
     ]
    }
   ],
   "source": [
    "# Run each model multiple times\n",
    "for i in range(0, 5):\n",
    "    run_name = \"TEST-SL_16_16_16__13__22_t-{}\".format(int(time.time())) # \"SL_16_16_16__13__22_t-{}\".format(int(time.time()))\n",
    "    tb = TensorBoard(log_dir=\".\\\\logs\\\\{}\".format(run_name))\n",
    "    model = model_generator(learning_rate=learning_rate, input_shape=training_videos.shape[1:])\n",
    "    history = train_model(run_name, tb, model, training_videos, training_rainfall)\n",
    "    print(\"Final loss: {}\".format(history.history[\"val_loss\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
