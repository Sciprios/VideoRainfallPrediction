{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Frame Model\n",
    "\n",
    "This script trains a single frame model based on an average image taken across the the forcasted month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "To begin, data for a single frame mnodel must be loaded along with the expected regional rainfall values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 New Training Data\n",
    "\n",
    "This section loads the new training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datafile = \"D:/PHD_DATA/Video_18-01-2021/prepared-data/single_all.npy\"\n",
    "training_rainfallfile = \"D:/PHD_DATA/Video_18-01-2021/prepared-data/expected_all.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_videos = np.load(training_datafile)\n",
    "training_rainfall = np.load(training_rainfallfile)[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_videos = np.swapaxes(training_videos, 1, 2)\n",
    "training_videos = np.swapaxes(training_videos, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_videos[:, :, :, 0] = (training_videos[:, :, :, 0] - np.min(training_videos[:, :, :, 0])) / (np.max(training_videos[:, :, :, 0]) - np.min(training_videos[:, :, :, 0]))\n",
    "training_videos[:, :, :, 1] = (training_videos[:, :, :, 1] - np.min(training_videos[:, :, :, 1])) / (np.max(training_videos[:, :, :, 1]) - np.min(training_videos[:, :, :, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 DEPRECATED\n",
    "\n",
    "This following section uses two separate datasets. Which is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_datafile = \"E:/31-12-2020/prepared-data/single_train.npy\"\n",
    "#validation_datafile = \"E:/31-12-2020/prepared-data/single_valid.npy\"\n",
    "#\n",
    "#training_rainfallfile = \"E:/31-12-2020/prepared-data/expected_train.npy\"\n",
    "#validation_rainfallfile = \"E:/31-12-2020/prepared-data/expected_valid.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_videos = np.load(training_datafile)\n",
    "#validation_videos = np.load(validation_datafile)\n",
    "#\n",
    "#training_rainfall = np.load(training_rainfallfile)[:, 2:]\n",
    "#validation_rainfall = np.load(validation_rainfallfile)[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need them in X, Y, COLOURS\n",
    "#training_videos = np.swapaxes(training_videos, 1, 2)\n",
    "#training_videos = np.swapaxes(training_videos, 2, 3)\n",
    "#\n",
    "#validation_videos = np.swapaxes(validation_videos, 1, 2)\n",
    "#validation_videos = np.swapaxes(validation_videos, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "#training_videos[:, :, :, 0] = (training_videos[:, :, :, 0] - np.min(training_videos[:, :, :, 0])) / (np.max(training_videos[:, :, :, 0]) - np.min(training_videos[:, :, :, 0]))\n",
    "#training_videos[:, :, :, 1] = (training_videos[:, :, :, 1] - np.min(training_videos[:, :, :, 1])) / (np.max(training_videos[:, :, :, 1]) - np.min(training_videos[:, :, :, 1]))\n",
    "#\n",
    "#validation_videos[:, :, :, 0] = (validation_videos[:, :, :, 0] - np.min(validation_videos[:, :, :, 0])) / (np.max(validation_videos[:, :, :, 0]) - np.min(validation_videos[:, :, :, 0]))\n",
    "#validation_videos[:, :, :, 1] = (validation_videos[:, :, :, 1] - np.min(validation_videos[:, :, :, 1])) / (np.max(validation_videos[:, :, :, 1]) - np.min(validation_videos[:, :, :, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definition\n",
    "\n",
    "Next, a CNN model architecture is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generator(input_shape=(2, 61, 121), learning_rate=0.1):\n",
    "    \"\"\" This method generates a model definition. \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First layer\n",
    "    model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Second layer\n",
    "    model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Third layer\n",
    "    model.add(Conv2D(16, (2, 2), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Final Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(13))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Setup training mechanism\n",
    "    model.compile(\n",
    "        loss=\"mean_squared_error\",\n",
    "        optimizer=Adam(learning_rate=learning_rate))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "Finally, training the model using the single framed data and opening a tensorboard instance with details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(run_name, tensorboard, model, xdata, ydata, models_folder=\"D:/PHD_DATA/Video_18-01-2021/models/\"):\n",
    "    \"\"\" Trains the given model with the given dataset. \"\"\"\n",
    "    history = model.fit(\n",
    "        xdata,\n",
    "        ydata,\n",
    "        batch_size=2,\n",
    "        validation_split=0.3,\n",
    "        callbacks=[tensorboard],\n",
    "        epochs=50\n",
    "    )\n",
    "    save_model(model, models_folder + run_name + \".mdl\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexible parameters\n",
    "learning_rate = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 191 samples, validate on 83 samples\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 4s 20ms/sample - loss: 10354.0891 - val_loss: 8203.5067\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 1s 8ms/sample - loss: 7465.1589 - val_loss: 8195.9841\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7512.1671 - val_loss: 8170.0028\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 7479.2583 - val_loss: 8178.2882\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 2s 8ms/sample - loss: 7466.9084 - val_loss: 8195.9589\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 2s 10ms/sample - loss: 7455.1478 - val_loss: 8207.5854\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7490.3007 - val_loss: 8318.3402\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7461.3991 - val_loss: 8152.4799\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7462.9735 - val_loss: 8236.6184\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7536.2006 - val_loss: 8177.5584\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7476.3708 - val_loss: 8218.5926\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 7459.0116 - val_loss: 8221.6506\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7462.1452 - val_loss: 8249.7525\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7504.5937 - val_loss: 8202.6990\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7454.9517 - val_loss: 8185.5608\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7432.8607 - val_loss: 8187.0530\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 2s 8ms/sample - loss: 7438.4583 - val_loss: 8196.3534\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7438.0591 - val_loss: 8171.8324\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 7444.2972 - val_loss: 8238.4548\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7502.2847 - val_loss: 8212.4085\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7457.5350 - val_loss: 8167.2178\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7453.9309 - val_loss: 8154.9234\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7492.2131 - val_loss: 8295.1090\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7453.5321 - val_loss: 8174.1871\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7466.3330 - val_loss: 8170.5108\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7444.5214 - val_loss: 8195.6426\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7422.6785 - val_loss: 8513.6962\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7524.0776 - val_loss: 8182.1761\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7489.7078 - val_loss: 8464.7193\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7534.9662 - val_loss: 8261.6483\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7407.6117 - val_loss: 8293.2096\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7492.7198 - val_loss: 8153.4443\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7457.8756 - val_loss: 8167.8362\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 7461.1597 - val_loss: 8247.9624\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7418.7607 - val_loss: 8165.0055\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7450.5832 - val_loss: 8160.7347\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7585.2467 - val_loss: 8192.7592\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7513.5907 - val_loss: 8334.0648\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7453.7580 - val_loss: 8184.6950\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7471.4108 - val_loss: 8153.7409\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7480.8553 - val_loss: 8188.9503\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7478.6387 - val_loss: 8400.6026\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7497.3940 - val_loss: 8532.7044\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7452.3959 - val_loss: 8281.4335\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7507.1903 - val_loss: 8195.2887\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7444.7672 - val_loss: 8194.9143\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7495.3438 - val_loss: 8205.9904\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7476.0826 - val_loss: 8225.8426\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7458.7730 - val_loss: 8163.5879\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7430.3832 - val_loss: 8375.9517\n",
      "Final loss: 8375.951732221856\n",
      "Train on 191 samples, validate on 83 samples\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 4s 21ms/sample - loss: 19890.5626 - val_loss: 9794.9370\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9148.8441 - val_loss: 9798.7489\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9143.5799 - val_loss: 9829.6495\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9136.3506 - val_loss: 9794.0977\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9143.5631 - val_loss: 9792.7353\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9122.7768 - val_loss: 9798.1469\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9144.5935 - val_loss: 9812.1319\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9140.5675 - val_loss: 9798.4146\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 9126.0844 - val_loss: 9874.8794\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9105.3117 - val_loss: 9793.1659\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9129.1694 - val_loss: 9819.1271\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9150.7463 - val_loss: 9789.1903\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9140.5935 - val_loss: 9804.8669\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9137.4485 - val_loss: 9866.4730\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9151.4101 - val_loss: 9788.5743\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9114.5636 - val_loss: 9789.2209\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 2s 8ms/sample - loss: 9193.4503 - val_loss: 9806.5118\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9131.9375 - val_loss: 9816.7270\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9132.1352 - val_loss: 9819.7768\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9129.9918 - val_loss: 9794.9552\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9126.6916 - val_loss: 9788.9040\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9127.6648 - val_loss: 9803.1608\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9131.1764 - val_loss: 9835.6484\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9137.2286 - val_loss: 9792.1259\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 1s 7ms/sample - loss: 9146.1049 - val_loss: 9804.5108\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 9144.6230 - val_loss: 9804.5624\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9147.2563 - val_loss: 9788.8181\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 9135.3543 - val_loss: 9838.6959\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 8ms/sample - loss: 9128.1961 - val_loss: 9826.2208\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9150.9038 - val_loss: 9876.8837\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9124.2937 - val_loss: 9998.2112\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 9163.9402 - val_loss: 9803.7552\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9119.1081 - val_loss: 9790.0543\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9115.1210 - val_loss: 9798.9262\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9157.8139 - val_loss: 9828.3730\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9121.1902 - val_loss: 9792.1603\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9131.2208 - val_loss: 9792.6100\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9133.6304 - val_loss: 9792.4180\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9131.8452 - val_loss: 9822.2960\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9120.8214 - val_loss: 9798.4863\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9120.9061 - val_loss: 9854.1897\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9135.9650 - val_loss: 9805.4732\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9131.5559 - val_loss: 9794.4938\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9117.1397 - val_loss: 9805.3266\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9132.5401 - val_loss: 9796.1638\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9119.5789 - val_loss: 9792.4450\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 2s 8ms/sample - loss: 9147.4421 - val_loss: 9872.6759\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9143.7041 - val_loss: 9830.5667\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 2s 8ms/sample - loss: 9160.9177 - val_loss: 9798.4597\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 9127.3047 - val_loss: 9789.2827\n",
      "Final loss: 9789.282664839044\n",
      "Train on 191 samples, validate on 83 samples\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 4s 22ms/sample - loss: 5634.2496 - val_loss: 4795.3875\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 2s 10ms/sample - loss: 4371.4006 - val_loss: 4381.6568\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 2s 10ms/sample - loss: 3982.9560 - val_loss: 4514.5040\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 2s 10ms/sample - loss: 4105.8189 - val_loss: 4494.5092\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 2s 10ms/sample - loss: 4205.3966 - val_loss: 4441.0795\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4020.3638 - val_loss: 4359.6492\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4023.2090 - val_loss: 4343.5963\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3993.3491 - val_loss: 4375.7170\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4023.3368 - val_loss: 4809.1929\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4010.1461 - val_loss: 4551.1998\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4111.4277 - val_loss: 4442.6313\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4072.6989 - val_loss: 4418.7114\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4043.8766 - val_loss: 4340.9420\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4010.8979 - val_loss: 4740.6219\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4019.7702 - val_loss: 4393.4325\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3960.6381 - val_loss: 4378.4777\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4014.1007 - val_loss: 4401.0327\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3958.3830 - val_loss: 4522.0413\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 4056.8109 - val_loss: 4487.2738\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 4026.8506 - val_loss: 4425.2922\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 2s 8ms/sample - loss: 4023.8899 - val_loss: 4399.9675\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4010.0117 - val_loss: 4390.9218\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4108.5213 - val_loss: 4352.4332\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4066.6622 - val_loss: 4344.5154\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4007.0401 - val_loss: 4430.4456\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4140.1755 - val_loss: 4404.1833\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4129.2607 - val_loss: 4369.9312\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4054.0160 - val_loss: 4597.3789\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4003.5777 - val_loss: 4368.0442\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3962.1080 - val_loss: 4351.8145\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4049.3458 - val_loss: 4644.4981\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4028.1361 - val_loss: 4351.1056\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4093.7319 - val_loss: 4509.8141\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4000.7808 - val_loss: 4752.3827\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 4201.9273 - val_loss: 4544.7804\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4047.5124 - val_loss: 4597.2166\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4149.2762 - val_loss: 4711.1527\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4131.4669 - val_loss: 4408.9845\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4018.3745 - val_loss: 4417.2728\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4039.6128 - val_loss: 4347.0929\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4024.2216 - val_loss: 4494.1647\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4134.7062 - val_loss: 4447.1554\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3976.0563 - val_loss: 4380.6780\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3979.5541 - val_loss: 4338.2182\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4168.7289 - val_loss: 4362.6383\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4002.1929 - val_loss: 4403.2251\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4026.2102 - val_loss: 4385.9505\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3963.3967 - val_loss: 4424.5346\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 1s 7ms/sample - loss: 4037.3620 - val_loss: 4324.5975\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 4023.0857 - val_loss: 4634.0954\n",
      "Final loss: 4634.095382506589\n",
      "Train on 191 samples, validate on 83 samples\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 4s 23ms/sample - loss: 8683.9550 - val_loss: 8635.5147\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 2s 11ms/sample - loss: 7413.6231 - val_loss: 7818.3494\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 2s 10ms/sample - loss: 7363.2742 - val_loss: 7820.2926\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 2s 10ms/sample - loss: 7345.8133 - val_loss: 7839.0308\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 2s 10ms/sample - loss: 7361.5539 - val_loss: 7828.5604\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7361.2779 - val_loss: 7930.0333\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 7378.3084 - val_loss: 8055.2100\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7384.0624 - val_loss: 7886.3265\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7352.3628 - val_loss: 7894.8697\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7346.7843 - val_loss: 7890.8432\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7430.4327 - val_loss: 7877.4856\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7438.8508 - val_loss: 7816.1632\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7438.5383 - val_loss: 7827.3761\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7367.9196 - val_loss: 7831.4430\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7450.8429 - val_loss: 7843.5427\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7351.5616 - val_loss: 7896.0561\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7380.1044 - val_loss: 7915.5411\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 7419.6577 - val_loss: 7865.4812\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7389.7722 - val_loss: 7872.8847\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7358.7467 - val_loss: 7929.3231\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7361.6626 - val_loss: 7841.0072\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7378.6070 - val_loss: 8174.9057\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 7358.0038 - val_loss: 8077.2431\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 7368.4382 - val_loss: 7875.9616\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7389.7412 - val_loss: 7901.1434\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7340.7898 - val_loss: 7833.4182\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 7362.8617 - val_loss: 7914.2078\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 2s 8ms/sample - loss: 7372.2135 - val_loss: 7848.1094\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7349.4339 - val_loss: 7926.2904\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7362.3367 - val_loss: 7873.5713\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7351.5481 - val_loss: 8010.8370\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7387.9165 - val_loss: 7860.7921\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7372.1323 - val_loss: 7841.4762\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7346.8596 - val_loss: 7875.8098\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7352.3358 - val_loss: 7855.8230\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7356.7499 - val_loss: 7828.8660\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7357.6152 - val_loss: 7851.3510\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7361.0214 - val_loss: 7876.5930\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7421.6326 - val_loss: 7904.8724\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7382.6914 - val_loss: 7952.0229\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7361.4074 - val_loss: 7905.6433\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7384.1353 - val_loss: 7846.4687\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7422.3044 - val_loss: 7850.4797\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7375.1801 - val_loss: 7832.2910\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7424.3402 - val_loss: 7905.9390\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7376.5897 - val_loss: 7824.7282\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7366.0403 - val_loss: 7833.3437\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7365.3058 - val_loss: 7844.1715\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7366.0489 - val_loss: 7817.9407\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 7351.9541 - val_loss: 8078.8816\n",
      "Final loss: 8078.881594738328\n",
      "Train on 191 samples, validate on 83 samples\n",
      "Epoch 1/50\n",
      "191/191 [==============================] - 5s 24ms/sample - loss: 7564.1776 - val_loss: 4229.2961\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3764.5761 - val_loss: 3979.4932\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3637.7997 - val_loss: 3973.6432\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3682.2387 - val_loss: 3938.2282\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3718.7246 - val_loss: 3935.1075\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3760.3198 - val_loss: 3923.3878\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3705.6014 - val_loss: 4119.7136\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3675.9660 - val_loss: 4161.2142\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3657.7530 - val_loss: 3915.9705\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3605.2066 - val_loss: 3957.8821\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3645.7254 - val_loss: 4061.0275\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 2s 9ms/sample - loss: 3687.2389 - val_loss: 3949.7310\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 1s 8ms/sample - loss: 3633.4003 - val_loss: 4151.8874\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 2s 8ms/sample - loss: 3707.8245 - val_loss: 4113.3296\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3728.9565 - val_loss: 3922.7099\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3614.8607 - val_loss: 3944.9364\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3671.8863 - val_loss: 3884.4133\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3841.5826 - val_loss: 3917.7027\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3656.2689 - val_loss: 4229.3025\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3589.3060 - val_loss: 3984.8873\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3614.4677 - val_loss: 3924.4502\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3624.3830 - val_loss: 3974.8044\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 1s 7ms/sample - loss: 3654.0869 - val_loss: 3975.2968\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 1s 6ms/sample - loss: 3653.6522 - val_loss: 4002.8983\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3691.2251 - val_loss: 3914.1380\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3749.9836 - val_loss: 4471.4518\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3752.8820 - val_loss: 3909.6348\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3652.4263 - val_loss: 3935.6029\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3778.9924 - val_loss: 4052.4305\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3637.4054 - val_loss: 4049.1616\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3741.3594 - val_loss: 3898.3902\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3697.3656 - val_loss: 4046.0052\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3773.6475 - val_loss: 3938.2667\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3655.5317 - val_loss: 3912.0367\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3633.4039 - val_loss: 3919.2715\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3922.3267 - val_loss: 3917.9238\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3791.0753 - val_loss: 3947.2273\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3611.9554 - val_loss: 4129.1461\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3643.8321 - val_loss: 4031.3952\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3695.1083 - val_loss: 3954.2505\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3714.6129 - val_loss: 3893.4195\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3725.2661 - val_loss: 4268.0038\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3667.9212 - val_loss: 4017.8542\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3733.7498 - val_loss: 4138.6142\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3685.3289 - val_loss: 3924.2685\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3673.6490 - val_loss: 3909.8711\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3675.7628 - val_loss: 4221.9098\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3742.7217 - val_loss: 4047.8285\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3605.9858 - val_loss: 4020.8262\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 1s 7ms/sample - loss: 3624.7042 - val_loss: 4203.1856\n",
      "Final loss: 4203.185605704066\n"
     ]
    }
   ],
   "source": [
    "# Run each model multiple times\n",
    "for i in range(0, 5):\n",
    "    run_name = \"SL_32_32_16__13__22_t-{}\".format(int(time.time()))\n",
    "    tb = TensorBoard(log_dir=\".\\\\logs\\\\{}\".format(run_name))\n",
    "    model = model_generator(learning_rate=learning_rate, input_shape=training_videos.shape[1:])\n",
    "    history = train_model(run_name, tb, model, training_videos, training_rainfall)\n",
    "    print(\"Final loss: {}\".format(history.history[\"val_loss\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
