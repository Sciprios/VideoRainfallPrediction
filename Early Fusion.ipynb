{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Fusion\n",
    "\n",
    "This script takes all frames at once and passes them through a cnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "To begin, data for a middle frames model must be loaded along with the expected regional rainfall values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datafile = \"E:/31-12-2020/prepared-data/middle_train.npy\"\n",
    "validation_datafile = \"E:/31-12-2020/prepared-data/middle_valid.npy\"\n",
    "\n",
    "training_rainfallfile = \"E:/31-12-2020/prepared-data/expected_train.npy\"\n",
    "validation_rainfallfile = \"E:/31-12-2020/prepared-data/expected_valid.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_videos = np.load(training_datafile)\n",
    "validation_videos = np.load(validation_datafile)\n",
    "\n",
    "training_rainfall = np.load(training_rainfallfile)[:, 2:]\n",
    "validation_rainfall = np.load(validation_rainfallfile)[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need them in X, Y, COLOURS\n",
    "training_videos = np.swapaxes(training_videos, 1, 2)\n",
    "training_videos = np.swapaxes(training_videos, 2, 3)\n",
    "training_videos = np.swapaxes(training_videos, 3, 4)\n",
    "\n",
    "validation_videos = np.swapaxes(validation_videos, 1, 2)\n",
    "validation_videos = np.swapaxes(validation_videos, 2, 3)\n",
    "validation_videos = np.swapaxes(validation_videos, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "training_videos[:, :, :, :, 0] = (training_videos[:, :, :, :, 0] - np.min(training_videos[:, :, :, :, 0])) / (np.max(training_videos[:, :, :, :, 0]) - np.min(training_videos[:, :, :, :, 0]))\n",
    "training_videos[:, :, :, :, 1] = (training_videos[:, :, :, :, 1] - np.min(training_videos[:, :, :, :, 1])) / (np.max(training_videos[:, :, :, :, 1]) - np.min(training_videos[:, :, :, :, 1]))\n",
    "\n",
    "validation_videos[:, :, :, :, 0] = (validation_videos[:, :, :, :, 0] - np.min(validation_videos[:, :, :, :, 0])) / (np.max(validation_videos[:, :, :, :, 0]) - np.min(validation_videos[:, :, :, :, 0]))\n",
    "validation_videos[:, :, :, :, 1] = (validation_videos[:, :, :, :, 1] - np.min(validation_videos[:, :, :, :, 1])) / (np.max(validation_videos[:, :, :, :, 1]) - np.min(validation_videos[:, :, :, :, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definition\n",
    "\n",
    "Next, a CNN model architecture is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generator(input_shape=(28, 2, 61, 121), learning_rate=0.1):\n",
    "    \"\"\" This method generates a model definition. \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First layer\n",
    "    model.add(Conv3D(16, (2, 2, 2), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    \n",
    "    # Second layer\n",
    "    model.add(Conv3D(16, (2, 2, 2), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    \n",
    "    # Third layer\n",
    "    model.add(Conv3D(8, (2, 2, 2), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    \n",
    "    # Final Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(13))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(13))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Setup training mechanism\n",
    "    model.compile(\n",
    "        loss=\"mean_squared_error\",\n",
    "        optimizer=Adam(learning_rate=learning_rate))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "Finally, training the model using the single framed data and opening a tensorboard instance with details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(run_name, tensorboard, model, xdata, ydata, models_folder=\"./models/\"):\n",
    "    \"\"\" Trains the given model with the given dataset. \"\"\"\n",
    "    model.fit(\n",
    "        xdata,\n",
    "        ydata,\n",
    "        batch_size=2,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[tensorboard],\n",
    "        epochs=50\n",
    "    )\n",
    "    save_model(model, models_folder + run_name + \".mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexible parameters\n",
    "learning_rate = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"early_fusion-three_layer-16168f2-222-lr_{}-{}\".format(learning_rate, int(time.time()))\n",
    "tb = TensorBoard(log_dir=\".\\\\logs\\\\{}\".format(run_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_generator(learning_rate=learning_rate, input_shape=training_videos.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143 samples, validate on 36 samples\n",
      "Epoch 1/50\n",
      "143/143 [==============================] - 41s 284ms/sample - loss: 42395.9974 - val_loss: 9947.3825\n",
      "Epoch 2/50\n",
      "143/143 [==============================] - 41s 285ms/sample - loss: 8675.6516 - val_loss: 9978.6487\n",
      "Epoch 3/50\n",
      "143/143 [==============================] - 38s 264ms/sample - loss: 8715.3417 - val_loss: 9948.6876\n",
      "Epoch 4/50\n",
      "143/143 [==============================] - 40s 280ms/sample - loss: 8691.0629 - val_loss: 9925.8339\n",
      "Epoch 5/50\n",
      "143/143 [==============================] - 28s 199ms/sample - loss: 8620.8191 - val_loss: 10053.5566\n",
      "Epoch 6/50\n",
      "143/143 [==============================] - 30s 207ms/sample - loss: 8612.4617 - val_loss: 9932.8554\n",
      "Epoch 7/50\n",
      "143/143 [==============================] - 27s 188ms/sample - loss: 8606.9343 - val_loss: 9932.3972\n",
      "Epoch 8/50\n",
      "143/143 [==============================] - 27s 187ms/sample - loss: 8632.9454 - val_loss: 9937.0879\n",
      "Epoch 9/50\n",
      "143/143 [==============================] - 28s 194ms/sample - loss: 8643.0021 - val_loss: 9926.8500\n",
      "Epoch 10/50\n",
      "143/143 [==============================] - 27s 190ms/sample - loss: 8636.9767 - val_loss: 9937.8612\n",
      "Epoch 11/50\n",
      "143/143 [==============================] - 34s 238ms/sample - loss: 8628.8340 - val_loss: 9952.1900\n",
      "Epoch 12/50\n",
      "143/143 [==============================] - 29s 202ms/sample - loss: 8631.7849 - val_loss: 10145.3820\n",
      "Epoch 13/50\n",
      "143/143 [==============================] - 29s 202ms/sample - loss: 8693.7739 - val_loss: 9933.2925\n",
      "Epoch 14/50\n",
      "143/143 [==============================] - 31s 217ms/sample - loss: 8646.3107 - val_loss: 9939.3960\n",
      "Epoch 15/50\n",
      "143/143 [==============================] - 30s 212ms/sample - loss: 8655.5934 - val_loss: 9950.2537\n",
      "Epoch 16/50\n",
      "143/143 [==============================] - 28s 198ms/sample - loss: 8622.2768 - val_loss: 9965.0421\n",
      "Epoch 17/50\n",
      "143/143 [==============================] - 27s 191ms/sample - loss: 8619.8937 - val_loss: 9932.4408\n",
      "Epoch 18/50\n",
      "143/143 [==============================] - 29s 200ms/sample - loss: 8635.8611 - val_loss: 9996.2009\n",
      "Epoch 19/50\n",
      "143/143 [==============================] - 31s 214ms/sample - loss: 8622.6853 - val_loss: 10065.6699\n",
      "Epoch 20/50\n",
      "143/143 [==============================] - 31s 217ms/sample - loss: 8607.8229 - val_loss: 9933.2224\n",
      "Epoch 21/50\n",
      "143/143 [==============================] - 28s 198ms/sample - loss: 8626.0844 - val_loss: 10049.8395\n",
      "Epoch 22/50\n",
      "143/143 [==============================] - 29s 200ms/sample - loss: 8612.9401 - val_loss: 9937.3879\n",
      "Epoch 23/50\n",
      "143/143 [==============================] - 27s 190ms/sample - loss: 8643.5850 - val_loss: 9931.1282\n",
      "Epoch 24/50\n",
      "143/143 [==============================] - 27s 186ms/sample - loss: 8625.5841 - val_loss: 10136.3572\n",
      "Epoch 25/50\n",
      "143/143 [==============================] - 27s 190ms/sample - loss: 8642.2282 - val_loss: 9927.3649\n",
      "Epoch 26/50\n",
      "143/143 [==============================] - 27s 191ms/sample - loss: 8629.1759 - val_loss: 10088.0982\n",
      "Epoch 27/50\n",
      "143/143 [==============================] - 27s 192ms/sample - loss: 8628.9620 - val_loss: 9962.5626\n",
      "Epoch 28/50\n",
      "143/143 [==============================] - 27s 187ms/sample - loss: 8648.2538 - val_loss: 9977.6299\n",
      "Epoch 29/50\n",
      "143/143 [==============================] - 27s 189ms/sample - loss: 8646.1534 - val_loss: 9924.6015\n",
      "Epoch 30/50\n",
      "143/143 [==============================] - 27s 187ms/sample - loss: 8669.2456 - val_loss: 9929.2513\n",
      "Epoch 31/50\n",
      "143/143 [==============================] - 28s 195ms/sample - loss: 8660.9570 - val_loss: 9960.7871\n",
      "Epoch 32/50\n",
      "143/143 [==============================] - 27s 187ms/sample - loss: 8642.5458 - val_loss: 9965.1091\n",
      "Epoch 33/50\n",
      "143/143 [==============================] - 27s 187ms/sample - loss: 8622.4365 - val_loss: 9931.5944\n",
      "Epoch 34/50\n",
      "143/143 [==============================] - 27s 189ms/sample - loss: 8616.9089 - val_loss: 10054.5940\n",
      "Epoch 35/50\n",
      "143/143 [==============================] - 27s 191ms/sample - loss: 8644.2671 - val_loss: 9934.4338\n",
      "Epoch 36/50\n",
      "143/143 [==============================] - 27s 186ms/sample - loss: 8617.5279 - val_loss: 9948.4946\n",
      "Epoch 37/50\n",
      "143/143 [==============================] - 27s 192ms/sample - loss: 8627.6202 - val_loss: 9952.6865\n",
      "Epoch 38/50\n",
      "143/143 [==============================] - 27s 186ms/sample - loss: 8623.2928 - val_loss: 9968.2849\n",
      "Epoch 39/50\n",
      "143/143 [==============================] - 27s 187ms/sample - loss: 8626.5913 - val_loss: 9976.1369\n",
      "Epoch 40/50\n",
      "143/143 [==============================] - 28s 194ms/sample - loss: 8712.5619 - val_loss: 9927.1690\n",
      "Epoch 41/50\n",
      "143/143 [==============================] - 27s 192ms/sample - loss: 8658.9081 - val_loss: 9961.4288\n",
      "Epoch 42/50\n",
      "143/143 [==============================] - 27s 189ms/sample - loss: 8622.9091 - val_loss: 9994.2030\n",
      "Epoch 43/50\n",
      "143/143 [==============================] - 27s 188ms/sample - loss: 8636.0467 - val_loss: 9943.8761\n",
      "Epoch 44/50\n",
      "143/143 [==============================] - 27s 186ms/sample - loss: 8629.4745 - val_loss: 10070.7741\n",
      "Epoch 45/50\n",
      "143/143 [==============================] - 27s 186ms/sample - loss: 8631.0445 - val_loss: 10092.9233\n",
      "Epoch 46/50\n",
      "143/143 [==============================] - 27s 187ms/sample - loss: 8668.0790 - val_loss: 9932.5842\n",
      "Epoch 47/50\n",
      "143/143 [==============================] - 27s 186ms/sample - loss: 8636.2908 - val_loss: 9942.5885\n",
      "Epoch 48/50\n",
      "143/143 [==============================] - 27s 185ms/sample - loss: 8611.6618 - val_loss: 9939.3625\n",
      "Epoch 49/50\n",
      "143/143 [==============================] - 27s 186ms/sample - loss: 8661.4899 - val_loss: 9934.3837\n",
      "Epoch 50/50\n",
      "143/143 [==============================] - 27s 185ms/sample - loss: 8652.5666 - val_loss: 9950.0858\n"
     ]
    }
   ],
   "source": [
    "train_model(run_name, tb, model, training_videos, training_rainfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
